- id: google_cloud_best_practices
  title: 'Five Best Practices for Using AI Coding Assistants'
  publisher: 'Google Cloud'
  published: '2024'
  accessed: '2026-02-02'
  url: 'https://cloud.google.com/blog/topics/developers-practitioners/five-best-practices-for-using-ai-coding-assistants'
  tags:
    - planning-and-structure
    - responsibility-oversight
  reading_descriptions:
    planning-and-structure: 'Practical guidance on planning, breaking down work, and setting context before asking AI to generate code.'
    responsibility-oversight: 'Highlights how upfront framing reduces downstream risk when AI accelerates implementation.'

- id: infoq_pdca_cycle
  title: 'Applying the PDCA Cycle to AI Code Generation'
  publisher: 'InfoQ'
  published: '2024'
  accessed: '2026-02-02'
  url: 'https://www.infoq.com/articles/PDCA-AI-code-generation/'
  tags:
    - planning-and-structure
  reading_descriptions:
    planning-and-structure: 'An exploration of using a Plan-Do-Check-Act loop with AI, grounding AI-assisted coding in established engineering process discipline.'

- id: graphite_ai_pair_programming
  title: 'AI Pair Programming Best Practices'
  publisher: 'Graphite'
  published: '2024'
  accessed: '2026-02-02'
  url: 'https://graphite.com/guides/ai-pair-programming-best-practices'
  tags:
    - planning-and-structure
  reading_descriptions:
    planning-and-structure: 'A practitioner-oriented guide on how context, constraints, and expectations shape the usefulness of AI coding output.'

- id: techradar_ai_security
  title: 'AI Is Creating Code Faster—but Also More Security Issues'
  publisher: 'TechRadar Pro'
  published: '2023'
  accessed: '2026-02-02'
  url: 'https://www.techradar.com/pro/ai-is-creating-code-faster-but-this-also-means-more-potential-security-issues'
  tags:
    - responsibility-oversight
    - governance-guardrails
  reading_descriptions:
    responsibility-oversight: 'A discussion of real-world risks that emerge when AI-generated code is adopted without sufficient design review or oversight.'
    governance-guardrails: 'Evidence that faster AI output requires explicit checks and security guardrails.'

- id: arxiv_human_centered_practices
  title: 'Human-Centered Practices for Responsible AI Development'
  repository: 'arXiv'
  published: '2023'
  accessed: '2026-02-02'
  url: 'https://arxiv.org/abs/2305.11248'
  tags:
    - responsibility-oversight
    - governance-guardrails
  reading_descriptions:
    responsibility-oversight: 'Research on how structured inputs, clear framing, and human supervision affect AI system behavior and reliability.'
    governance-guardrails: 'Covers oversight practices that translate into organizational guardrails.'

- id: boehm_software_engineering_economics
  author: 'Barry W. Boehm'
  title: 'Software Engineering Economics'
  publisher: 'Prentice Hall'
  published: '1981'
  accessed: '2026-02-02'
  url: 'https://www.cs.cmu.edu/~johnl/temple/18-749/papers/boehm1981.pdf'
  tags:
    - engineering-judgment
  reading_descriptions:
    engineering-judgment: 'A foundational text on why detecting problems earlier in the lifecycle is cheaper and more effective than fixing them later.'

- id: ericsson_deliberate_practice
  author: 'K. Anders Ericsson, Ralf T. Krampe, Clemens Tesch-Römer'
  title: 'The Role of Deliberate Practice in the Acquisition of Expert Performance'
  journal: 'Psychological Review, Vol. 100, No. 3'
  published: '1993'
  accessed: '2026-02-02'
  url: 'https://psycnet.apa.org/record/1993-40718-001'
  tags:
    - engineering-judgment
  reading_descriptions:
    engineering-judgment: 'Classic research on how expert judgment improves through focused, reflective practice rather than repetition alone.'

- id: dora_ai_assisted_report
  title: '2025 DORA State of AI-Assisted Software Development report'
  publisher: 'Google Cloud'
  published: '2025-09-23'
  accessed: '2026-01-30'
  url: 'https://cloud.google.com/resources/content/2025-dora-ai-assisted-software-development-report'
  tags:
    - ai-production-scale
  reading_descriptions:
    ai-production-scale: 'DORA’s 2025 report explaining that AI amplifies existing organizational capabilities.'

- id: microsoft_ai_code_nypost
  title: 'Microsoft CEO Satya Nadella says 30% of code now written by AI'
  publisher: 'New York Post'
  published: '2025-04-30'
  accessed: '2026-01-30'
  url: 'https://nypost.com/2025/04/30/business/microsoft-ceo-satya-nadella-says-30-of-code-now-written-by-ai/'
  tags:
    - ai-production-scale
  reading_descriptions:
    ai-production-scale: 'Reporting on Satya Nadella’s remarks about the share of Microsoft code written by AI.'

- id: adtmag_ai_coding_oversight
  title: 'Tech Leaders Embrace AI Coding Tools While Demanding Strict Oversight'
  publisher: 'ADTMag'
  published: '2025-09-10'
  accessed: '2026-01-30'
  url: 'https://adtmag.com/articles/2025/09/10/tech-leaders-embrace-ai-coding-tools-while-demanding-strict-oversight.aspx'
  tags:
    - governance-guardrails
  reading_descriptions:
    governance-guardrails: 'Survey results on human review requirements for AI-generated code.'

- id: arxiv_safe_ai_framework
  title: 'SAFE-AI Framework: Preventing Failures in AI-Driven Software Engineering'
  repository: 'arXiv'
  published: '2025-08-15'
  accessed: '2026-01-30'
  url: 'https://arxiv.org/abs/2508.11824'
  tags:
    - governance-guardrails
  reading_descriptions:
    governance-guardrails: 'Academic guidance on guardrails, sandboxing, and runtime verification for AI-driven software engineering.'

- id: arxiv_security_degradation_ai_code
  title: 'Security Degradation in Iterative AI Code Generation -- A Systematic Analysis of the Paradox'
  repository: 'arXiv'
  published: '2025-05-19'
  accessed: '2026-02-02'
  url: 'https://arxiv.org/abs/2506.11022'
  tags:
    - governance-guardrails
    - tooling-guardrails
  reading_descriptions:
    governance-guardrails: 'Evidence that iterative AI code refinement can increase vulnerabilities without strong verification.'
    tooling-guardrails: 'Quantifies security regression across iterations, supporting the need for automated scanning between AI edits.'

- id: arxiv_context_engineering_multi_agent
  title: 'Context Engineering for Multi-Agent LLM Code Assistants Using Elicit, NotebookLM, ChatGPT, and Claude Code'
  repository: 'arXiv'
  published: '2025-08-09'
  accessed: '2026-02-02'
  url: 'https://arxiv.org/abs/2508.08322'
  tags:
    - tooling-guardrails
  reading_descriptions:
    tooling-guardrails: 'Describes a multi-agent workflow with role decomposition and validation that improves reliability in code assistants.'

- id: arxiv_resttsllm_api_testing
  title: 'Combining TSL and LLM to Automate REST API Testing: A Comparative Study'
  repository: 'arXiv'
  published: '2025-09-05'
  accessed: '2026-02-02'
  url: 'https://arxiv.org/abs/2509.05540'
  tags:
    - tooling-guardrails
  reading_descriptions:
    tooling-guardrails: 'Shows how LLMs can automate test generation from API specifications, improving test coverage discipline.'

- id: eleventy_image_plugin
  title: 'Eleventy Image'
  publisher: 'Eleventy'
  accessed: '2025-02-14'
  url: 'https://www.11ty.dev/docs/plugins/image/'

- id: eleventy_fetch_plugin
  title: 'Fetch'
  publisher: 'Eleventy'
  accessed: '2025-02-14'
  url: 'https://www.11ty.dev/docs/plugins/fetch/'

- id: eleventy_dev_server
  title: 'Eleventy Dev Server'
  publisher: 'Eleventy'
  accessed: '2025-02-14'
  url: 'https://www.11ty.dev/docs/dev-server/'
